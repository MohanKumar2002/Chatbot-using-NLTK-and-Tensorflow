{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohanKumar2002/Chatbot-using-NLTK-and-Tensorflow/blob/master/Chatbot_with_nltk_and_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OCYiycUBSAt",
        "outputId": "2dbf030d-9257-4aa4-f202-2bcc0f354112"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "source": [
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "intents = json.loads(open('/content/intents.json').read())\n",
        "\n",
        "words = pickle.load(open('/content/words.pkl', 'rb'))\n",
        "classes = pickle.load(open('/content/classes.pkl', 'rb'))\n",
        "model = load_model('/content/chatbotmodel.h5')\n",
        "\n",
        "def clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [lemmatizer.lemmatize(word)  for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "def bag_of_words(sentence):\n",
        "    sentence_words= clean_up_sentence(sentence)\n",
        "    bag = [0] * len(words)\n",
        "    for w in sentence_words:\n",
        "        for i, word in enumerate(words):\n",
        "            if word == w:\n",
        "                bag[i] = 1\n",
        "\n",
        "    return np.array(bag)\n",
        "\n",
        "def predict_class(sentence):\n",
        "    bow = bag_of_words(sentence)\n",
        "    res = model.predict(np.array([bow]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "\n",
        "    results.sort(key=lambda  x:x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
        "    return return_list\n",
        "\n",
        "\n",
        "def get_response(intents_list,intents_json):\n",
        "    tag= intents_list[0]['intent']\n",
        "    list_of_intents =intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if i['tag'] == tag:\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "print(\" Welcome to Cube AI Tech Solutions \")\n",
        "print(\"Ask your any query about our Company\")\n",
        "while True:\n",
        "    message = input(\"| You: \")\n",
        "    if message == \"bye\" or message == \"Goodbye\":\n",
        "        ints = predict_class(message)\n",
        "        res = get_response(ints, intents)\n",
        "        print(\"| Bot:\", res)\n",
        "        print(\"The Program End here!\")\n",
        "        exit()\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        ints = predict_class(message)\n",
        "        res = get_response(ints, intents)\n",
        "        print(\"| Bot:\", res)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BhQqznyY-qnK",
        "outputId": "70146e24-1cb3-448f-a31a-6b15bdadd53c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Welcome to Cube AI Tech Solutions \n",
            "Ask your any query about our Company\n",
            "| You: course\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "| Bot: Informatics College Pokhara has been in direct partnership with London Metropolitan University, \n",
            "UK to provide enviable higher education in IT and Business to students in Pokhara.\n",
            "For Bachelors Degree in Information Technology we have been offering the specialization in BSc (Hons) Computing.\n",
            "For Bachelors in Business Administration we have been offering the followings:\n",
            "\n",
            "1. BBA (Marketing) with International Business \n",
            "\n",
            "2. BBA (Accounting & Finance) with International Business\n",
            "\n",
            "3. BBA (International Business)\n",
            "| You: bye\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "| Bot: Goodbye\n",
            "The Program End here!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J4x_YpOHRNM4",
        "outputId": "a69dda0b-6df8-4cc7-9579-b0d82feb5fc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.8)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load intents data\n",
        "with open('/content/intents.json') as file:\n",
        "    intents = json.load(file)\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "print(\"|============= Welcome to College Bot =============|\")\n",
        "print(\"|======================== Feel Free ==========================|\")\n",
        "print(\"|============================ To =============================|\")\n",
        "print(\"|================ Ask your any query about our Company =======|\")\n",
        "\n",
        "def generate_response(input_text):\n",
        "    # Find the intent that matches the input_text pattern\n",
        "    for intent in intents['intents']:\n",
        "        if any(pattern.lower() in input_text.lower() for pattern in intent['patterns']):\n",
        "            # If a matching pattern is found, use the intent's responses\n",
        "            return random.choice(intent['responses'])\n",
        "\n",
        "    # If no pattern matches, use GPT-2 to generate a response\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    output = model.generate(input_ids, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"| You: \")\n",
        "\n",
        "    if user_input.lower() in [\"bye\", \"goodbye\"]:\n",
        "        print(\"| Bot: Goodbye! Have a nice day.\")\n",
        "        break\n",
        "\n",
        "    # Generate response\n",
        "    bot_response = generate_response(user_input)\n",
        "    print(\"| Bot:\", bot_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kb-B9s9Rkrq",
        "outputId": "e236d5d8-a463-4eb0-8f4b-12c2a1cf8809"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|============= Welcome to Cube AI Tech Solutions =============|\n",
            "|======================== Feel Free ==========================|\n",
            "|============================ To =============================|\n",
            "|================ Ask your any query about our Company =======|\n",
            "| You: hi\n",
            "| Bot: Hello!\n",
            "| You: how are you\n",
            "| Bot: Sorry, can't understand you\n",
            "| You: where are you\n",
            "| Bot: Please give me more info\n",
            "| You: what courses you offering\n",
            "| Bot: Please give me more info\n",
            "| You: what is your name\n",
            "| Bot: I'm Ribot\n",
            "| You: what courses are available\n",
            "| Bot: Informatics College Pokhara has been in direct partnership with London Metropolitan University, \n",
            "UK to provide enviable higher education in IT and Business to students in Pokhara.\n",
            "For Bachelors Degree in Information Technology we have been offering the specialization in BSc (Hons) Computing.\n",
            "For Bachelors in Business Administration we have been offering the followings:\n",
            "\n",
            "1. BBA (Marketing) with International Business \n",
            "\n",
            "2. BBA (Accounting & Finance) with International Business\n",
            "\n",
            "3. BBA (International Business)\n",
            "| You: course duration\n",
            "| Bot: Please give me more info\n",
            "| You: how much the college fee\n",
            "| Bot: Sorry, can't understand you\n",
            "| You: how much is the college fee\n",
            "| Bot: Course BIT\n",
            "Admission fee=RS 96,000\n",
            "Year 1\n",
            "University and Exam fee= RS 100,000 Each semester fee=RS 69,000 Total fee= RS 334,000\n",
            "Year 2\n",
            "University and Exam fee= RS 100,000 Each semester fee=RS 69,000 Total fee= RS 238,000\n",
            "Year 3\n",
            "University and Exam fee= RS 100,000 Each semester fee=RS 69,000 Total fee= RS 238,000\n",
            "GrandTotal fee= RS 810,000\n",
            "\n",
            "Course BBA\n",
            "Admission fee=RS 96,000\n",
            "Year 1\n",
            "University and Exam fee= RS 100,000 Each semester fee=RS 52,000 Total fee= RS 300,000\n",
            "Year 2\n",
            "University and Exam fee= RS 100,000 Each semester fee=RS 52,000 Total fee= RS 204,000\n",
            "Year 3\n",
            "University and Exam fee= RS 100,000 Each semester fee=RS 52,000 Total fee= RS 204,000\n",
            "Year 4\n",
            "University and Exam fee= RS 50,000 Semester fee=RS 52,000 Total fee= RS 102,000\n",
            "GrandTotal fee= RS 810,000\n",
            "| You: bye\n",
            "| Bot: Goodbye! Have a nice day.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvi+bY62DNfy2VmNBxjtQ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}